{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "allting_insights.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPmxCKZJqTSIXr0pyO1bVVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kat-tian/Allting/blob/master/allting_insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McGO7c2-Thuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "from typing import Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.cloud import firestore\n",
        "import os\n",
        "\n",
        "import functools\n",
        "from itertools import chain\n",
        "from typing import Dict, List, TypeVar\n",
        "from datetime import datetime\n",
        "\n",
        "from google.cloud import firestore\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GCLOUD_PROJECT\"] = \"stage-allting\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./google_credentials.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2JtD-GbL2ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def normalize(val, min, max):\n",
        "    return (val - min) / (max - min)\n",
        "\n",
        "\n",
        "def get_deviation(mean, compare_num, min, max):\n",
        "    return normalize(compare_num, min, max) - normalize(mean, min, max)\n",
        "\n",
        "\n",
        "def none_fill(arr):\n",
        "    new_list = []\n",
        "    if len([i for i in arr if i]) == 0:\n",
        "        return []\n",
        "    for i, v in enumerate(arr):\n",
        "        if i == 0:\n",
        "            new_list.append(recursive_none_fill(v, i, arr))\n",
        "        else:\n",
        "            new_list.append(recursive_none_fill(new_list[-1], i, arr))\n",
        "    return new_list\n",
        "\n",
        "\n",
        "def recursive_none_fill(prev, idx, arr):\n",
        "    current = arr[idx]\n",
        "    if len(arr) == idx + 1:\n",
        "        if current is not None:\n",
        "            return current\n",
        "        else:\n",
        "            if prev is None:\n",
        "                return np.mean([i for i in arr if i])\n",
        "            return prev\n",
        "\n",
        "    if current is None:\n",
        "        next_val = recursive_none_fill(current, idx + 1, arr)\n",
        "        if prev is None:\n",
        "            return next_val\n",
        "        return (next_val + prev) / 2\n",
        "    return current\n",
        "\n",
        "\n",
        "\n",
        "def meeting_mean(meeting_idx) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    arg1: List of\n",
        "    {\n",
        "    'Description': str,\n",
        "    'FeedbackId': str,\n",
        "    'Order': int,\n",
        "    'UserId': str',\n",
        "    'Value': str'\n",
        "    }\n",
        "\n",
        "    Returns:\n",
        "    dict:keys are questionId and value avg values for each question in question_group\n",
        "\n",
        "    \"\"\"\n",
        "    values_dict = {}\n",
        "    for response in meeting_idx:\n",
        "        feedback_id = response['FeedbackId']\n",
        "\n",
        "        value = response[\"Value\"]\n",
        "        if feedback_id not in values_dict:\n",
        "            values_dict[feedback_id] = [value]\n",
        "        else:\n",
        "            values_dict[feedback_id].append(value)\n",
        "\n",
        "    for key, value in values_dict.items():\n",
        "        if len(value) != 0:\n",
        "            values_dict[key] = np.mean(value).item()\n",
        "\n",
        "    return values_dict\n",
        "\n",
        "\n",
        "def parse_raw_feedback(meetings) -> Dict[str, List[float]]:\n",
        "    \"\"\"\n",
        "    :param meetings: raw meetings type from firestore\n",
        "    :return: a parsed dict of radio and slider results merged\n",
        "    \"\"\"\n",
        "    all_means: Dict[str, List[float]] = {}\n",
        "\n",
        "    for idx, meeting in enumerate(meetings):\n",
        "        mean_obj = meeting_mean(meetings[idx][\"SliderResults\"])\n",
        "        radio_res = meetings[idx][\"RadioResults\"]\n",
        "        for val in radio_res:\n",
        "            if val[\"Value\"] == 'no':\n",
        "                val[\"Value\"] = 0\n",
        "            else:\n",
        "                val[\"Value\"] = 1\n",
        "\n",
        "        mean_obj.update(meeting_mean(radio_res))\n",
        "\n",
        "        for question_id, mean in mean_obj.items():\n",
        "            if question_id not in all_means:\n",
        "                all_means[question_id] = [mean]\n",
        "            else:\n",
        "                all_means[question_id].append(mean)\n",
        "\n",
        "    return all_means\n",
        "\n",
        "\n",
        "def parse_special_types(meetings) -> Dict[str, List]:\n",
        "    \"\"\"\n",
        "      :param meetings: raw meetings type from firestore\n",
        "      :return: a parsed dict of special value types with a list containing None and floats\n",
        "      \"\"\"\n",
        "    all_means: Dict[str, List[float]] = {\n",
        "        \"Hour\": [],\n",
        "        \"Weekday\": [],\n",
        "        \"SpeakerDistribution\": [],\n",
        "        \"NumParticipants\": [],\n",
        "        \"Length\": [],\n",
        "    }\n",
        "\n",
        "    # TODO: Deal with missing values?\n",
        "    for idx, meeting in enumerate(meetings):\n",
        "\n",
        "        all_means[\"Length\"].append(meeting.get(\"Length\"))\n",
        "        all_means[\"NumParticipants\"].append(meeting.get(\"NumParticipants\"))\n",
        "\n",
        "        timestamp = meeting.get(\"MeetingTimestamp\")\n",
        "        if timestamp:\n",
        "            date_time = datetime.fromtimestamp(timestamp / 1000)  # Divide by 1000 since value is in milliseconds\n",
        "            hour = date_time.hour\n",
        "            weekday = date_time.isoweekday()\n",
        "            all_means[\"Hour\"].append(hour)\n",
        "            all_means[\"Weekday\"].append(weekday)\n",
        "        else:\n",
        "            all_means[\"Hour\"].append(None)\n",
        "            all_means[\"Weekday\"].append(None)\n",
        "\n",
        "        speaker_distribution = meeting.get(\"SpeakerDistribution\")\n",
        "        if speaker_distribution:\n",
        "            even_dist = 1 / len(speaker_distribution)\n",
        "            dist_num = functools.reduce(lambda store, nextVal: store + abs(nextVal - even_dist),\n",
        "                                        [0, *chain(speaker_distribution)])\n",
        "\n",
        "            # results in a score from 0 to 1 where 0 is perfect speaker distribution and 1 is one person talking only\n",
        "            distribution_score = normalize(dist_num, 0, 1 - even_dist)\n",
        "            all_means[\"SpeakerDistribution\"].append(distribution_score)\n",
        "        else:\n",
        "            all_means[\"SpeakerDistribution\"].append(None)\n",
        "\n",
        "    return all_means\n",
        "\n",
        "\n",
        "def fill_mean(values: List[float], length: int) -> List[float]:\n",
        "    list_len = len(values)\n",
        "    if list_len == 0:\n",
        "        return []\n",
        "    if length < list_len:\n",
        "        raise Exception(\"length must be longer than list, list length: {}, length {}\".format(list_len, length))\n",
        "\n",
        "    mean = np.mean(values)\n",
        "    return [*chain([mean for i in range(length - list_len)], values)]\n",
        "\n",
        "\n",
        "def get_min_max_data(raw):\n",
        "    \"\"\"\n",
        "       :param\n",
        "       :return:\n",
        "       \"\"\"\n",
        "\n",
        "    results = {}\n",
        "    for idx, meeting in enumerate(raw):\n",
        "        slider_list = raw[idx][\"SliderResults\"]\n",
        "        radio_list = raw[idx][\"RadioResults\"]\n",
        "        for s in slider_list:\n",
        "            obj = {}\n",
        "            obj[\"Min\"] = s[\"Min\"]\n",
        "            obj[\"Max\"] = s[\"Max\"]\n",
        "            results[s[\"FeedbackId\"]] = obj\n",
        "\n",
        "        for r in radio_list:\n",
        "            obj = {}\n",
        "            obj[\"Min\"] = 0\n",
        "            obj[\"Max\"] = 1\n",
        "            results[r[\"FeedbackId\"]] = obj\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_correlations(means: Dict[str, List[float]]) -> Dict[str, List[Dict[str, float]]]:\n",
        "    corr_matrix = np.corrcoef([*means.values()])\n",
        "    keys = [*means.keys()]\n",
        "    output = {}\n",
        "    for idx, key in enumerate(keys):\n",
        "        output[key] = []\n",
        "        for row_idx, value in enumerate(corr_matrix[idx]):\n",
        "            if keys[row_idx] != key and not np.isnan(value):\n",
        "                output[key].append({keys[row_idx]: value})\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def main(meeting_id, team_id, org_id, meeting_timestamp):\n",
        "\n",
        "\n",
        "\n",
        "    print(meeting_id, team_id, org_id, meeting_timestamp)\n",
        "\n",
        "    db = firestore.Client()\n",
        "\n",
        "    raw_feedback = db.collection(u'feedback-results') \\\n",
        "        .where(u\"TeamId\", u\"==\", team_id) \\\n",
        "        .where(u\"OrgId\", u\"==\", org_id) \\\n",
        "        .where(u\"MeetingTimestamp\", u\"<=\", meeting_timestamp).stream()\n",
        "\n",
        "    feedback_list = []\n",
        "    for feedback in raw_feedback:\n",
        "        meet = feedback.to_dict()\n",
        "        feedback_list.append(meet)\n",
        "\n",
        "    if len(feedback_list) == 0:\n",
        "        print(\"No meetings to compare with\")\n",
        "        return\n",
        "\n",
        "    question_values_dict = parse_raw_feedback(feedback_list)\n",
        "    special_types_dict = parse_special_types(feedback_list)\n",
        "\n",
        "    for k, v in special_types_dict.items():\n",
        "      print(k,v , none_fill(v))\n",
        "      special_types_dict[k] = none_fill(v)\n",
        "    \n",
        "    \n",
        "    len_dict = {}\n",
        "\n",
        "    longest_count = 0\n",
        "    for key, value in question_values_dict.items():\n",
        "        length = len(value)\n",
        "        len_dict[key] = length\n",
        "        if length > longest_count:\n",
        "            longest_count = length\n",
        "\n",
        "    for question_id, values in question_values_dict.items():\n",
        "        if len(values) < longest_count:\n",
        "            question_values_dict[question_id] = fill_mean(values, longest_count)\n",
        "\n",
        "    correlations = get_correlations(question_values_dict)\n",
        "\n",
        "    results_list = []\n",
        "    # Here we add all relevant items to the results_list that is to be returned\n",
        "    for key, val in correlations.items():\n",
        "        corr_list = []\n",
        "        for obj in val:\n",
        "            sub_key = list(obj.keys())[0]\n",
        "            value = list(obj.values())[0]\n",
        "            corr_list.append({\"QuestionId\": sub_key, \"Value\": value})\n",
        "        results_list.append({\"QuestionId\": key, \"Values\": corr_list, \"DataPoints\": len_dict[key]})\n",
        "\n",
        "    series_data = []\n",
        "    min_max_data = get_min_max_data(feedback_list)\n",
        "\n",
        "    for key, val in question_values_dict.items():\n",
        "        prevMean = np.mean(val[:-1])\n",
        "        min_max = min_max_data[key]\n",
        "        series_data.append(\n",
        "            {\"QuestionId\": key, \"Values\": val, \"PreMean\": prevMean, \"Mean\": np.mean(val), \"CurrentVal\": val[-1],\n",
        "             \"Min\": min_max[\"Min\"], \"Max\": min_max[\"Max\"],\n",
        "             \"Deviation\": get_deviation(prevMean, val[-1], min_max[\"Min\"], min_max[\"Max\"])})\n",
        "\n",
        "    return [correlations, series_data, special_types_dict]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJtSC7b3UW5Q",
        "colab_type": "code",
        "outputId": "8ad0ee0c-97b0-498a-b4bb-dfb3ca516f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "db = firestore.Client()\n",
        "current_feedback_doc_id = u'5ZSG8ESc5TDsVVl78KrX'\n",
        "current_meeting = db.collection(u'feedback-results').document(current_feedback_doc_id).get().to_dict()\n",
        "latest_meeting_timestamp = current_meeting[u'MeetingTimestamp']\n",
        "team_id = current_meeting[u'TeamId']\n",
        "org_id = current_meeting[u'OrgId']\n",
        "print(latest_meeting_timestamp, team_id, org_id)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1588057349425 lLot1shBDwLRD2CR46PX iQFX5Oe0nHv7OisCV3V9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyi-AWbGUu9q",
        "colab_type": "code",
        "outputId": "7b0b4e74-9e4f-4b92-958c-9aab5250b826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "[correlations, feedbackData, special_types_dict] = main(current_feedback_doc_id, team_id, org_id, latest_meeting_timestamp )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5ZSG8ESc5TDsVVl78KrX lLot1shBDwLRD2CR46PX iQFX5Oe0nHv7OisCV3V9 1588057349425\n",
            "Hour [17, 15, 15, 10, 21, 7] [17, 15, 15, 10, 21, 7]\n",
            "Weekday [3, 4, 3, 6, 5, 2] [3, 4, 3, 6, 5, 2]\n",
            "SpeakerDistribution [0.6656034795215656, 0.9907852564102564, 0.7283502198432421, 0.2276007215874924, None, 0.25919356745890976] [0.6656034795215656, 0.9907852564102564, 0.7283502198432421, 0.2276007215874924, 0.24339714452320108, 0.25919356745890976]\n",
            "NumParticipants [4, 4, 4, 4, 4, 4] [4, 4, 4, 4, 4, 4]\n",
            "Length [3800, 4000, 8000, 2000, 3600, 2580] [3800, 4000, 8000, 2000, 3600, 2580]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSi1F_GkT5cK",
        "colab_type": "text"
      },
      "source": [
        "## Continuous Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrY6MR4SNe2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #NOTE: This particular regression example doesn't work; need to onehot encode \n",
        "  def new_predicted_y(x_var, y_var, x_pred, input_dict, print_relation=True): \n",
        "    \"\"\"\n",
        "    this function is the same as the previous predicted y function, \n",
        "    but made this more general. Can use with any input dict. \n",
        "    \"\"\"\n",
        "    x = input_dict.get(x_var)\n",
        "    y = input_dict.get(y_var)\n",
        "\n",
        "    model = np.polyfit(x,y,2)\n",
        "    predict = np.poly1d(model)\n",
        "\n",
        "    if print_relation: \n",
        "      print(\"When {} has a value of {}, {} has a value of: {}.\"\n",
        "      .format(x_var, x_pred, y_var, round(predict(x_pred),2)))\n",
        "\n",
        "    return predict(x_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdMoQvCjOWix",
        "colab_type": "code",
        "outputId": "024817f4-3d5a-40b2-c617-5151d0829d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "new_predicted_y(\"Weekday\", \"SpeakerDistribution\", 4, special_types_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When Weekday has a value of 4, SpeakerDistribution has a value of: 0.77.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7675625995640554"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FSd6s6RP05S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scatter_plot(x_var, y_var, input_dict):\n",
        "  \"\"\"\n",
        "  x_var: (str) x-var from dict key \n",
        "  y_var: (str) y-var from dict key\n",
        "  input_dict: (dict) dict to extract data \n",
        "\n",
        "  returns: (plt) scatter plot of x,y \n",
        "  \"\"\"\n",
        "  plt.scatter(input_dict.get(x_var), input_dict.get(y_var))\n",
        "  plt.xlabel(x_var)\n",
        "  plt.ylabel(y_var)\n",
        "  plt.title(\"Scatter: {} by {}\".format(x_var, y_var))\n",
        "\n",
        "  return plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-d6IyVo-uWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_strong_correlations(correlations_dict, thresh=0.5):\n",
        "  \"\"\"\n",
        "  correlations_dict: (dict) \n",
        "  thresh: (float)\n",
        "\n",
        "  returns: (dict) correlations where magnitude \n",
        "  is less/greater than thresh \n",
        "  \"\"\"\n",
        "  temp = {}\n",
        "  for idx,val in enumerate(correlations_dict):\n",
        "    iter_range = len(correlations_dict[idx])\n",
        "    question_id = val['QuestionId']\n",
        "    \n",
        "    if question_id not in temp.keys():\n",
        "      temp[question_id] = [x.get(\"QuestionId\") for x in val[\"Values\"] if x.get(\"Value\") > thresh or x.get(\"Value\") < -thresh]\n",
        "  \n",
        "  strong_corr = {k:v for k, v in temp.items() if len(v) > 0}\n",
        "  \n",
        "  return strong_corr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iixOO12UNrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_regressor_vals(feedback_dict):\n",
        "  \"\"\"\n",
        "  feedback_dict: (dict)\n",
        "  \n",
        "  returns: (dict) contains only question_id and \n",
        "  values for regression \n",
        "  \"\"\"\n",
        "  regressor_vals = {}\n",
        "  for idx, val in enumerate(feedbackData):\n",
        "    question_id = feedbackData[idx].get(\"QuestionId\")\n",
        "    \n",
        "    if question_id not in regressor_vals.keys():\n",
        "      regressor_vals[question_id] = feedbackData[idx][\"Values\"] \n",
        "  \n",
        "  return regressor_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC-Xv5qXVHp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predicted_y (x_var, y_var, x_pred, print_relation = False):\n",
        "  \"\"\"\n",
        "  x_var: (str) x-val question_id key\n",
        "  y_var: (str) y-val question_id key \n",
        "\n",
        "  x_pred: (float/int) x-val to predict on \n",
        "  print_relation: (bool) True = print on, False = print off\n",
        "\n",
        "  returns: (float/int) predicted y-val for given x-val\n",
        "  \"\"\"\n",
        "  regressor_vals = get_regressor_vals(feedbackData)\n",
        "  x = regressor_vals[x_var]\n",
        "  y = regressor_vals[y_var]\n",
        "\n",
        "  model = np.polyfit(x,y,1)\n",
        "  predict = np.poly1d(model)\n",
        "\n",
        "  if print_relation: \n",
        "    print(\"When {} has a value of {}, {} has a value of: {}.\"\n",
        "    .format(x_var, x_pred, y_var, round(predict(x_pred),2)))\n",
        "\n",
        "  return predict(x_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa9ok6wZNzZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relative_difference(low_val, high_val, x_var, y_var, print_relation=False):\n",
        "  #TODO: Define directions of relations [higher/lower, increase/decrease]\n",
        "  \"\"\"\n",
        "  low_val: (float/int) low number for x-val\n",
        "  high_val: (float/int) high number for x-val\n",
        "\n",
        "  x_var: (str) x-val question_id key\n",
        "  y_var: (str) y-val question_id key \n",
        "\n",
        "  returns: (float) percent difference of y_var when x_var has high or low values \n",
        "  \"\"\"\n",
        "  \n",
        "  low = predicted_y(x_var, y_var, low_val)\n",
        "  high = predicted_y(x_var, y_var, high_val)\n",
        "\n",
        "  difference = round(((high-low)/low)*100, 2)\n",
        "\n",
        "  if difference > 0:\n",
        "    relation = \"higher\"\n",
        "  else: \n",
        "    relation = \"lower\"\n",
        "\n",
        "\n",
        "  if print_relation: \n",
        "    print(\"When {} has a value of {}, {} has a {}% {} score compared to when {} has a value of {}. \"\n",
        "    .format(x_var, high_val, y_var, difference, relation, x_var, low_val))\n",
        "\n",
        "  return difference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthqAz_CI9MH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_differences(low_val, high_val, strong_corr_dict):\n",
        "  \"\"\"\n",
        "  low_val: (float/int) low number for x-val\n",
        "  high_val: (float/int) high number for x-val\n",
        "\n",
        "  strong_corr_dict: (dict) cleaned correlations with only ids \n",
        "\n",
        "  returns: (dict) keys = ids, value = relative difference in values \n",
        "  \"\"\"\n",
        "  relations = {}\n",
        "\n",
        "  for k, v in strong_corr_dict.items():\n",
        "    x_var = k\n",
        "    if len(v) > 1:\n",
        "      for i in range(len(v)):\n",
        "        y_var = v[i]\n",
        "        update_key = \"{}:{}\".format(x_var, y_var)\n",
        "        if update_key not in relations.keys():\n",
        "          relations[update_key] = relative_difference(low_val, high_val, x_var, y_var)\n",
        "    else: \n",
        "      y_var = v[0]\n",
        "      update_key = \"{}:{}\".format(x_var, y_var)\n",
        "      if update_key not in relations.keys():\n",
        "        relations[update_key] = relative_difference(low_val,high_val, x_var, y_var)\n",
        "\n",
        "  return relations\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "909baOIFDpPk",
        "colab_type": "code",
        "outputId": "47856f49-9b24-4d88-cfd4-f4e46f6cde5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "store_differences(1, 5, get_strong_correlations(correlations))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-66f377daced9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstore_differences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_strong_correlations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-fb53fcb4ae93>\u001b[0m in \u001b[0;36mget_strong_correlations\u001b[0;34m(correlations_dict, thresh)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelations_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0miter_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mquestion_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QuestionId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AruWsUWhRv1z",
        "colab_type": "text"
      },
      "source": [
        "## Categorical Predictions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Srnx-kS2sk",
        "colab_type": "text"
      },
      "source": [
        "#### Group by categorical iv, get mean of dv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XXhLwC55evg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use me to combine special dict and regressor dict \n",
        "def combine_dict(dict1, dict2):\n",
        "  \"\"\"\n",
        "  dict1: (dict) first dictonary to combine\n",
        "  dict2: (dict) second dictonary to combine\n",
        "\n",
        "  returns: merged dict of dict1, dict2\n",
        "  \"\"\"\n",
        "  return {**dict1, **dict2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5RwgH9gSLNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#send combined dict here, get mean values for dv grouped by categorical iv \n",
        "def categorical_means(dict, iv, dv, print_relation=False, return_highest=False):\n",
        "  \"\"\"\n",
        "  dict: (dict) contains categorical predictors \n",
        "  iv: (str) label for categorical predictor\n",
        "  dv: (str) label for value to predict on \n",
        "\n",
        "  return_highest=True: \n",
        "  returns: (dict) {key: categorical, value: mean of dv}\n",
        "  for only the highest mean value for dv\n",
        "  \n",
        "  return_highest=False: \n",
        "  returns: (dict) {key: categorical, value: mean of dv}\n",
        "  for all values \n",
        "  \"\"\"\n",
        "  df = pd.DataFrame.from_dict(dict)\n",
        "  grouped = df.groupby(iv).mean()\n",
        "  dv_ol = grouped[dv].sort_values(ascending=False).to_dict()\n",
        "\n",
        "  if print_relation:\n",
        "    for k, v in dv_ol.items(): \n",
        "      print(\"When {} is {}, the average value for {} is {}\".format(iv, k, dv, v))\n",
        "\n",
        "  if return_highest: \n",
        "    return {list(dv_ol.keys())[0], list(dv_ol.values())[0]}\n",
        "  else: \n",
        "    return dv_ol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wavMayLSxCB",
        "colab_type": "code",
        "outputId": "25158db7-82c2-48aa-b86f-3f7116fa8d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#call the functions\n",
        "merged = combine_dict(special_types_dict, get_regressor_vals(feedbackData))\n",
        "categorical_means(merged, 'Weekday', '1a')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 6.25,\n",
              " 3: 4.416666666666666,\n",
              " 4: 4.666666666666667,\n",
              " 5: 5.0,\n",
              " 6: 4.666666666666667}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUKDikCdiLGz",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression with categoricals "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJXstvSsuWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI729Tw9iXZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dummy(dict, var, return_df=False):\n",
        "  \"\"\"\n",
        "  dict: (dict) dict to get dummies\n",
        "  var: (str) label for the categorical var\n",
        "\n",
        "  return_df = True: \n",
        "  returns: (df) categorical dummy coded\n",
        "  return_df=False:\n",
        "  returns: (dict) categorical dummy coded\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.DataFrame.from_dict(special_types_dict)\n",
        "  ohe = pd.get_dummies(df[var])\n",
        "\n",
        "  df.drop(columns=[var], inplace=True)\n",
        "  final_df = df.join(ohe)\n",
        "\n",
        "  ohe_dict = final_df.to_dict()\n",
        "\n",
        "  #removes nested dicts \n",
        "  new_dict = {}\n",
        "  for k, v in ohe_dict.items(): \n",
        "    x = list(v.values())\n",
        "    if k not in new_dict:\n",
        "      new_dict[k] = x\n",
        "\n",
        "  if return_df: \n",
        "    return pd.DataFrame.from_dict(new_dict)\n",
        "  else: \n",
        "    return new_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USEpkV8hj-4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dict for categorical regression \n",
        "cat_regression = pd.DataFrame.from_dict({**get_regressor_vals(feedbackData), \n",
        "                       **create_dummy(special_types_dict, 'Weekday')})\n",
        "\n",
        "#update column names to str \n",
        "cat_regression.columns = cat_regression.columns.astype(str)\n",
        "cat_regression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAsr6WbTmCO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(ivs, dv, predictors,df):\n",
        "  \"\"\"\n",
        "  iv:(list) feature list \n",
        "  dv:(str) outcome to predict\n",
        "  predictors: (list) specific values of \n",
        "  iv to predict on \n",
        "\n",
        "  returns:(float) prediction\n",
        "  \"\"\"\n",
        "  X = df[ivs]\n",
        "  y = df[dv]\n",
        "  reg = LinearRegression().fit(X, y)\n",
        "  \n",
        "  return reg.predict([predictors])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeHzhn-3sZGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8bf714b-9423-45d7-951e-6f38a6fe3f93"
      },
      "source": [
        "get_predictions(['2', '3', '4', '5', '6'], '3a', [0, 0, 0, 0, 1] , cat_regression)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.33333333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeIjMDsrgNYe",
        "colab_type": "text"
      },
      "source": [
        "### Scrapwork "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rome78YrgPaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame.from_dict(special_types_dict) #convert dict to df\n",
        "gropued_weekday = df.groupby('Weekday').mean() # create df where grouped by mean\n",
        "\n",
        "\n",
        "one_hot = pd.get_dummies(df['Weekday']) #create one_hot encoding\n",
        "one_hot\n",
        "\n",
        "new_df = df.drop(columns= ['Weekday']).join(one_hot) #join one_hot encoding\n",
        "one_hot_dict = new_df.to_dict() #create dict with one-hot encoded vals\n",
        "\n",
        "one_hot_dict\n",
        "\n",
        "new_dict = {}\n",
        "for k, v in one_hot_dict.items(): \n",
        "    x = list(v.values())\n",
        "    if k not in new_dict:\n",
        "      new_dict[k] = x\n",
        "\n",
        "#very simple approach to the weekdays problem, groupby day of the week, \n",
        "#calculate mean of dv, compare to others and find optimal...\n",
        "#too much chance? \n",
        "#remember to drop one dummy variable column to avoid multicolinarity (since data can be derived)\n",
        "\n",
        "\n",
        "regressor_df = pd.DataFrame.from_dict(get_regressor_vals(feedbackData))\n",
        "one_hot_df = pd.DataFrame.from_dict(one_hot_dict)\n",
        "\n",
        "pd.concat([regressor_df, one_hot_df], ignore_index=True, axis=0)\n",
        "# one_hot_df = pd.DataFrame.from_dict(combined)\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# model = LinearRegression()\n",
        "# one_hot_df.head()\n",
        "\n",
        "#TODO \n",
        "#I need to get these things from the one hot encoding into non-nested dicts\n",
        "#so I can combine it with the the get_regressor_vals dict\n",
        "#this can be used to do regression on categorical data\n",
        "\n",
        "categorical = [\"Hour\", \"Weekday\"]\n",
        "#TODO: calculate relations between categorical and continious vars\n",
        "#TODO: calculate relations between categorical and categorical vars\n",
        "\n",
        "#Idea, group by continous DV mean for each level of categorical (e.g., weekday)\n",
        "\n",
        "#group by all the days of the week \n",
        "#take the mean for the corresponding dependent variable "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}